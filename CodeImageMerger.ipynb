{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "License\n",
      "\n",
      "Dependencies\n",
      "\n",
      "Latest Version of README\n",
      "\n",
      "Cr)\n",
      "\n",
      "About\n",
      "\n",
      "This package contains an OCR engine - (1ibtesseract and a command line program - (tesseract -\n",
      "\n",
      "Tesseract 4 adds a new neural net (LSTM) based OCR engine which is focused on Ii\n",
      "supports the legacy Tesseract OCR engine of Tesseract 3 which works by recognizing character patterns. Compatibility\n",
      "with Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0). It also needs traineddata files which\n",
      "support the legacy engine, for example those from the tessdata repository.\n",
      "\n",
      "@ recognition, but also still\n",
      "\n",
      "‘Stefan Weil is the current lead developer. Ray Smith was the lead developer until 2018. The maintainer is Zdenko\n",
      "\n",
      "Podobny. For a list of contributors see AUTHORS and GitHub’s log of cont\n",
      "\n",
      "Tesseract has unicode (UTF-8) support, and can recognize more than 100 languages “out of the box\".\n",
      "\n",
      "Tesseract supports various image formats including PNG, JPEG and TIFF.\n",
      "Tesseract supports various output formats: plain text. hOCR (HTML), PDF, invisible-text-only PDF, TSV and ALTO.\n",
      "You should note that in many cases, in order to get better OCR results, you'll need to improve the quality of the\n",
      "image you are giving Tesseract.\n",
      "\n",
      "This project does not include a GUI application. If you need one, please see the 3rdParty documentation.\n",
      "\n",
      "Tesseract can be trained to recognize other languages. See Tesseract Training for more information.\n",
      "\n",
      "Brief history\n",
      "\n",
      "Tesseract was originally developed at Hewlett-Packard Laboratories Bristol UK and at Hewlett-Packard Co, Greeley\n",
      "Colorado USA between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some\n",
      "\n",
      "C+ +izing in 1998. In 2005 Tesseract was open sourced by HP. From 2006 until November 2018 it was developed by\n",
      "Google.\n",
      "\n",
      "Major version 5 is the current stable version and started with release 5.0.0 on November 30, 2021. Newer minor\n",
      "\n",
      "versions and bugfix versions are available from GitHub.\n",
      "\n",
      "and planning\n",
      "\n",
      "Latest source code is available from main branch on GitHub. Open issues can be found in issue tracker,\n",
      "\n",
      "documentation.\n",
      "\n",
      "Images stitched successfully! Check 'stitched_image.jpg'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your images (replace 'image1.jpg' and 'image2.jpg' with actual filenames)\n",
    "image1 = cv2.imread('image1.jpg')\n",
    "image2 = cv2.imread('image2.jpg')\n",
    "\n",
    "# Create a Stitcher object\n",
    "stitcher = cv2.Stitcher_create()\n",
    "\n",
    "# Stitch the images\n",
    "status, stitched_image = stitcher.stitch([image1, image2])\n",
    "\n",
    "if status == cv2.Stitcher_OK:\n",
    "    cv2.imwrite('stitched_image.jpg', stitched_image)\n",
    "\n",
    "    # Extract text using Tesseract\n",
    "    pure_text = pytesseract.image_to_string(stitched_image)\n",
    "    print(pure_text)\n",
    "\n",
    "    print(\"Images stitched successfully! Check 'stitched_image.jpg'.\")\n",
    "else:\n",
    "    print(\"Stitching failed. Check if the images have enough overlapping features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'void RTControlle:\\n\\n{\\n\\n| if dispatch(synchronous)\\nwaitForEvents();\\n\\ni // 1430\\n\\n3\\n\\nawaitResponse(void)\\n\\nOneDelivered)\\n\\nvoid RTController:\\n{\\n\\naccept Incoming(void)\\n\\nshort bits;\\n| short priority;\\n—mutex->enter() ;\\nif ((bits = incomingBits)\\n{\\n\\ninternalBits |= bits;\\n| incomingBits = 0;\\ni do\\npo\\npriority = topPriority[bits];\\n\\nbits *= (short)(1 << priority);\\ncounts. peakMessagesALlLocated += (unsigned)incomingQ[priority] .size();\\ninternalQ[priority] . appendFrom(incomingQ[priority]);\\n\\n} while (bits != 6\\n\\n~mutex->leave();\\n// 1430\\nBa\\nvoid RTController: :countActorDestroy(void)\\nt\\n| counts.actorsDestroyed += 1U;\\nFs\\n\\nvoid RTController: :countActorIncarnate(void)\\nt\\n\\nmutex->enter() ;\\ncounts .actorsIncarnated++;\\nmutex->Leave();\\n\\nvoid RTControLler: : countMessageTransfer(RTMessage *msg)\\n£\\n© &G& msg->getSignal() == RTTimeoutsignal)\\n\\nif (msg->sapQ)\\n{\\n\\n}\\n\\nelse\\n\\nif\\n\\nRTAssert(counts.messagesAllocated\\ncounts.messagesAlLocated-—;\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
